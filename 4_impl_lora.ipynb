{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uIBC4MXHaHEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t7CAdnwyaHEa"
      },
      "outputs": [],
      "source": [
        "from capas_gpt import TransformerBlock, LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9Ssl0mpYaHEb"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        tok_embeds = self.tok_emb(input_ids)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=input_ids.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "t0a1k4Adkvwy"
      },
      "outputs": [],
      "source": [
        "with open(\"config_gpt.json\", \"r\") as f:\n",
        "    cfg = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU31qU6DaHEe",
        "outputId": "721f2446-e3c7-4fec-c485-e42082a8179d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1280)\n",
              "  (pos_emb): Embedding(1024, 1280)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (24): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (25): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (26): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (27): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (28): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (29): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (30): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (31): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (32): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (33): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (34): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (35): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"modelo_gpt_custom.pth\"\n",
        "\n",
        "model = GPTModel(cfg)\n",
        "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i4baIDiKI0tc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model,tokenizer,prompt,seed=42,max_new_tokens=50,temperature=0.9,top_k=50,top_p=0.95,repetition_penalty=1.1):\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        input_ids_cropped = generated_ids[:, -cfg[\"context_length\"]:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids_cropped)\n",
        "            logits = outputs[\"logits\"][:, -1, :]\n",
        "\n",
        "        for token_id in set(generated_ids[0].tolist()):\n",
        "            logits[0, token_id] /= repetition_penalty\n",
        "\n",
        "        logits = logits / temperature\n",
        "\n",
        "        if top_k > 0:\n",
        "            values, _ = torch.topk(logits, top_k)\n",
        "            threshold = values[:, -1].unsqueeze(-1)\n",
        "            logits[logits < threshold] = -float(\"Inf\")\n",
        "\n",
        "        if top_p < 1.0:\n",
        "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "            probs = F.softmax(sorted_logits, dim=-1)\n",
        "            cumulative_probs = torch.cumsum(probs, dim=-1)\n",
        "\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1].clone()\n",
        "            sorted_indices_to_remove[:, 0] = False\n",
        "\n",
        "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "            logits[0, indices_to_remove] = -float(\"Inf\")\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        generated_ids = torch.cat((generated_ids, next_token), dim=1)\n",
        "\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    output_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBBj5QXaO1RA",
        "outputId": "c3f1df34-dba4-4d05-ec81-6b6041519f6e"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sYX9R_cYN2Kz"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ndy1MICpaHEf"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class LoRALayer(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.alpha * (x @ self.A @ self.B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5g2OvZ_VaHEh"
      },
      "outputs": [],
      "source": [
        "class LinearWithLoRA(torch.nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(\n",
        "            linear.in_features, linear.out_features, rank, alpha\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c3N58b8RaHEi"
      },
      "outputs": [],
      "source": [
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, torch.nn.Linear) and any(x in name.lower() for x in [\"q\", \"k\", \"v\", \"proj\", \"fc\"]):\n",
        "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
        "        else:\n",
        "            replace_linear_with_lora(module, rank, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAYM7IXEaHEi",
        "outputId": "96c43cc6-c6ea-4313-ab67-361b5f81da2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters before: 838,359,040\n",
            "Total trainable parameters after: 0\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters before: {total_params:,}\")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters after: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra4UTEZjaHEj",
        "outputId": "8e6c620f-0e65-476b-e234-557841f3fdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable LoRA parameters: 5,898,240\n"
          ]
        }
      ],
      "source": [
        "replace_linear_with_lora(model, rank=16, alpha=16)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agLJxRgnaHEj",
        "outputId": "deadb1b6-615f-49f0-d9f1-bab211c41bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 1280)\n",
            "  (pos_emb): Embedding(1024, 1280)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (12): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (13): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (14): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (15): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (16): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (17): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (18): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (19): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (20): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (21): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (22): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (23): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (24): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (25): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (26): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (27): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (28): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (29): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (30): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (31): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (32): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (33): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (34): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (35): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_key): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (W_value): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (out_proj): LinearWithLoRA(\n",
            "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (lora): LoRALayer()\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"modelo_lora.pth\", map_location=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFaADazDImr5"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def historia_interactiva(model, tokenizer, prompt_inicial, pasos=10, tokens_por_paso=40, device=\"cpu\"):\n",
        "    contexto = prompt_inicial.strip()\n",
        "\n",
        "    for paso in range(pasos):\n",
        "        print(f\"\\n---------- Paso {paso + 1} ----------\\n\")\n",
        "        print(\"Historia hasta ahora:\\n\" + contexto + \"...\\n\")\n",
        "\n",
        "        print(\"Generando opciones...\\n\")\n",
        "\n",
        "        opcion1 = generate_text(model, tokenizer, contexto, max_new_tokens=tokens_por_paso,\n",
        "                                  temperature=0.9, top_k=40, seed=paso * 2)\n",
        "        opcion2 = generate_text(model, tokenizer, contexto, max_new_tokens=tokens_por_paso,\n",
        "                                  temperature=1.1, top_k=40, seed=paso * 2 + 1)\n",
        "\n",
        "        print(\"Opcin 1:\\n...\", textwrap.fill(opcion1[len(contexto):].strip(), width=80))\n",
        "        print(\"\\nOpcin 2:\\n...\", textwrap.fill(opcion2[len(contexto):].strip(), width=80))\n",
        "\n",
        "        eleccion = input(\"\\nElige 1 o 2: \").strip().lower()\n",
        "\n",
        "        if eleccion == \"2\" or eleccion == \"dos\":\n",
        "            contexto = opcion2.strip()\n",
        "        elif eleccion == \"fin\":\n",
        "            break\n",
        "        else:\n",
        "            contexto = opcion1.strip()\n",
        "        clear_output(wait=True)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(\"\\nHistoria completa:\\n\")\n",
        "    print(textwrap.fill(contexto, width=80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Historia completa:\n",
            "\n",
            "He opened the door and there it was  not human, not anymore. Hello? The voice spoke to her with a gentle yet menacing tone. She could feel its presence but she couldnt figure out what made its presence so peculiar. It wasnt like it bothered the others. It seemed to just exist as a thing that kept repeating the same sound each time through the day. For some reason, no matter how loud\n"
          ]
        }
      ],
      "source": [
        "prompt_inicial = input(\"Escribe el inicio de tu historia (o djalo vaco para que empiece la historia la IA automticamente):\\n> \").strip()\n",
        "if prompt_inicial == \"\":\n",
        "    prompts = [\n",
        "    \"It was a quiet night until the phone rang unexpectedly.\",\n",
        "    \"Deep in the forest, something ancient had awakened.\",\n",
        "    \"She never expected the letter to arrive after all these years.\",\n",
        "    \"The sky turned red as the city fell silent.\",\n",
        "    \"I was walking home when I saw the shadow move.\",\n",
        "    \"The mirror in the attic began to whisper again.\",\n",
        "    \"No one believed him when he said he saw a ghost at school.\",\n",
        "    \"Every night, the same dream. Every night, a little closer.\",\n",
        "    \"They thought it was just a power outage... until the screams began.\",\n",
        "    \"He opened the door and there it was  not human, not anymore.\"\n",
        "    ]\n",
        "    prompt_inicial = random.choice(prompts)\n",
        "\n",
        "historia_interactiva(model, tokenizer, prompt_inicial, pasos=10, tokens_por_paso=40)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "025b85be9f0c4c87978af47df6ffe907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fff1fcc925049beba1589f4f5b52eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba4ff798c3b4fde992284db0251c186",
            "placeholder": "",
            "style": "IPY_MODEL_4bdc07fa89dc4555802ff04f0983411f",
            "value": "Map:100%"
          }
        },
        "17166d092aaa43c1b6a5717dea97f172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "241dd8f4004b4a8090e75fb1d37542b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba8ac187fa548538cff3bf1e4d4fe29",
            "placeholder": "",
            "style": "IPY_MODEL_dc974d881c534c3ea72904ebe81cf1ad",
            "value": "727/727[00:12&lt;00:00,59.82examples/s]"
          }
        },
        "30e175a666fe4f148a57aaca53a3ff72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "391615cea97246e6a1ef33b5bfb8a03a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c5024701a394e14b303098a83a032b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d5e8a44f374c4695ab3dab6f6b8762",
              "IPY_MODEL_96a7feb501144f3fa87ce6cd8d35392d",
              "IPY_MODEL_5476281a2785430685a79bd779171261"
            ],
            "layout": "IPY_MODEL_391615cea97246e6a1ef33b5bfb8a03a"
          }
        },
        "44d5e8a44f374c4695ab3dab6f6b8762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf885e6376a471c87cc67c65dbc8daf",
            "placeholder": "",
            "style": "IPY_MODEL_b2671f32abef40c88f92958c2fd3b2a0",
            "value": "Generatingtrainsplit:"
          }
        },
        "4aaab19804604d29945be46468396fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63803bee233c4174a56829beb9d47da9",
            "placeholder": "",
            "style": "IPY_MODEL_30e175a666fe4f148a57aaca53a3ff72",
            "value": "Map:100%"
          }
        },
        "4bdc07fa89dc4555802ff04f0983411f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5476281a2785430685a79bd779171261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5b404ed5e0449fb44aea739f6ef19f",
            "placeholder": "",
            "style": "IPY_MODEL_7dc49080d7b949408fdce9768e078656",
            "value": "727/0[00:00&lt;00:00,4554.71examples/s]"
          }
        },
        "5ba8ac187fa548538cff3bf1e4d4fe29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe8dde7647d4309b94ec7480cf0c600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb80774e55c848a0b3716942a0ac7dc5",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_025b85be9f0c4c87978af47df6ffe907",
            "value": 727
          }
        },
        "63803bee233c4174a56829beb9d47da9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72539527c4ef40fb9bcc47bccc6b75e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc49080d7b949408fdce9768e078656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf885e6376a471c87cc67c65dbc8daf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a7feb501144f3fa87ce6cd8d35392d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f6731ba61c4da097c649e2b476087f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaf291aa97234bbeaa13a26246876a8b",
            "value": 1
          }
        },
        "a7f6731ba61c4da097c649e2b476087f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b2671f32abef40c88f92958c2fd3b2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2697fe8caff47a984ac9529600b5498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e157dcae93ed49ff8308c492f75664a7",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e332227cfb444c6fac5986fdea962f21",
            "value": 727
          }
        },
        "bb2ea5270a924fe188554a3ffc66e6da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29b8a168a6546c888f46c015d2e9567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3bb5dd9a43349c39a219a32edb45b38",
            "placeholder": "",
            "style": "IPY_MODEL_17166d092aaa43c1b6a5717dea97f172",
            "value": "727/727[00:02&lt;00:00,536.04examples/s]"
          }
        },
        "dba4ff798c3b4fde992284db0251c186": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc974d881c534c3ea72904ebe81cf1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e157dcae93ed49ff8308c492f75664a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e332227cfb444c6fac5986fdea962f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3bb5dd9a43349c39a219a32edb45b38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b00cb096e94b9e8b63828eadd3d2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fff1fcc925049beba1589f4f5b52eee",
              "IPY_MODEL_b2697fe8caff47a984ac9529600b5498",
              "IPY_MODEL_d29b8a168a6546c888f46c015d2e9567"
            ],
            "layout": "IPY_MODEL_72539527c4ef40fb9bcc47bccc6b75e3"
          }
        },
        "eaf291aa97234bbeaa13a26246876a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb80774e55c848a0b3716942a0ac7dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5b404ed5e0449fb44aea739f6ef19f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52c0422277a4340b2fb18f1fa5b5f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aaab19804604d29945be46468396fb7",
              "IPY_MODEL_5fe8dde7647d4309b94ec7480cf0c600",
              "IPY_MODEL_241dd8f4004b4a8090e75fb1d37542b6"
            ],
            "layout": "IPY_MODEL_bb2ea5270a924fe188554a3ffc66e6da"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
