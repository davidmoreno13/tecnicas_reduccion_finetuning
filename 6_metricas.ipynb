{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIBC4MXHaHEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t7CAdnwyaHEa"
      },
      "outputs": [],
      "source": [
        "from capas_gpt import TransformerBlock, LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Ssl0mpYaHEb"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        tok_embeds = self.tok_emb(input_ids)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=input_ids.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t0a1k4Adkvwy"
      },
      "outputs": [],
      "source": [
        "with open(\"config_gpt.json\", \"r\") as f:\n",
        "    cfg = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU31qU6DaHEe",
        "outputId": "721f2446-e3c7-4fec-c485-e42082a8179d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1280)\n",
              "  (pos_emb): Embedding(1024, 1280)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (24): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (25): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (26): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (27): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (28): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (29): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (30): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (31): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (32): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (33): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (34): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (35): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"modelo_gpt_custom.pth\"\n",
        "\n",
        "modelo_base = GPTModel(cfg)\n",
        "modelo_base.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "modelo_base.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4baIDiKI0tc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model,tokenizer,prompt,seed=42,max_new_tokens=50,temperature=0.9,top_k=50,top_p=0.95,repetition_penalty=1.1):\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        input_ids_cropped = generated_ids[:, -cfg[\"context_length\"]:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids_cropped)\n",
        "            logits = outputs[\"logits\"][:, -1, :]\n",
        "\n",
        "        for token_id in set(generated_ids[0].tolist()):\n",
        "            logits[0, token_id] /= repetition_penalty\n",
        "\n",
        "        logits = logits / temperature\n",
        "\n",
        "        if top_k > 0:\n",
        "            values, _ = torch.topk(logits, top_k)\n",
        "            threshold = values[:, -1].unsqueeze(-1)\n",
        "            logits[logits < threshold] = -float(\"Inf\")\n",
        "\n",
        "        if top_p < 1.0:\n",
        "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "            probs = F.softmax(sorted_logits, dim=-1)\n",
        "            cumulative_probs = torch.cumsum(probs, dim=-1)\n",
        "\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1].clone()\n",
        "            sorted_indices_to_remove[:, 0] = False\n",
        "\n",
        "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "            logits[0, indices_to_remove] = -float(\"Inf\")\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        generated_ids = torch.cat((generated_ids, next_token), dim=1)\n",
        "\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    output_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBBj5QXaO1RA",
        "outputId": "c3f1df34-dba4-4d05-ec81-6b6041519f6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DAVID SM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYX9R_cYN2Kz"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo_base.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_texts = [\n",
        "    \"The night was quiet, and the leaves rustled softly as I walked through the forest. I didn't know exactly where I was going, only that I felt drawn forward.\",\n",
        "    \"She had always found thunderstorms calming, but that evening the lightning flashes felt different. There was something electric in the air, something she couldn't name.\",\n",
        "    \"I found an old book in the attic, filled with unfamiliar symbols. As I flipped through the pages, a faint hum seemed to rise from the paper itself.\",\n",
        "    \"He woke up in a hospital room with no memory of how he got there. The hallway outside was dark, and the machines next to him were silent.\",\n",
        "    \"At first, the apartment seemed perfectly ordinary. But small things started changing—doors left open, lights turned on, whispers in the night.\",\n",
        "    \"The plane had landed safely, but we were rerouted through a strange airport with no signs. None of the staff would speak to us.\",\n",
        "    \"Someone kept knocking at the front door at exactly the same time every night. When I opened it, there was never anyone there.\",\n",
        "    \"We found an old camera while hiking. The photos inside showed places we hadn't been to yet—and people we hadn't met.\",\n",
        "    \"He didn't like going into the basement, but the strange noise forced him to check. Everything looked normal, but the air felt heavy.\",\n",
        "    \"I caught a glimpse of a shadow behind me in the mirror. When I turned around, the room was empty and still.\",\n",
        "    \"They said not to enter the old building on the edge of town. It was abandoned, but I saw lights moving inside late at night.\",\n",
        "    \"My daughter started drawing strange shapes in her notebook. When I asked about them, she said she learned them in a dream.\",\n",
        "    \"The fog was dense as we drove through the mountain road. Figures seemed to appear and disappear along the roadside.\",\n",
        "    \"Each morning, I woke up to find objects moved slightly out of place. No one else in the house noticed anything.\",\n",
        "    \"We built the cabin to get away from the city. At first it was peaceful, but then we started hearing footsteps on the porch at night.\",\n",
        "    \"A small box arrived in the mail with no sender listed. Inside was a folded piece of paper with only a date written on it.\",\n",
        "    \"The town seemed friendly and calm, but I noticed something strange: the same people walked the same routes every single day.\",\n",
        "    \"There's a door in the basement that doesn't match the rest of the house. It's locked, and we don't have the key.\",\n",
        "    \"My dog refuses to enter the guest room. He just stares at the doorway and growls, even when no one is there.\",\n",
        "    \"To understand why I was waking up so tired, I recorded myself sleeping. The recording picked up soft sounds I couldn't explain.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"It was a quiet night when I heard a knock on the door.\",\n",
        "    \"Once upon a time in a forgotten land,\",\n",
        "    \"She opened the old journal and began to read.\",\n",
        "    \"The lights started flickering, and then everything went dark.\",\n",
        "    \"I was walking through the forest when I saw something move.\",\n",
        "    \"He never liked elevators, but that day he had no choice.\",\n",
        "    \"The last thing I remember was the scream.\",\n",
        "    \"She whispered something before vanishing into the mist.\",\n",
        "    \"They told us not to go into the basement.\",\n",
        "    \"No one believed him until the blood appeared.\",\n",
        "    \"I love Sundays. The calm, the coffee, the silence.\",\n",
        "    \"We were late to the airport, but something told me to stop.\",\n",
        "    \"I turned the corner and found a puppy in a box.\",\n",
        "    \"The stars were brighter than ever that night.\",\n",
        "    \"She received a letter with no return address.\",\n",
        "    \"This was supposed to be a normal camping trip.\",\n",
        "    \"He had always feared the ocean, but today was different.\",\n",
        "    \"The dream felt more real than usual.\",\n",
        "    \"I heard laughter from the attic.\",\n",
        "    \"Suddenly, the phone rang—at 3 a.m.\",\n",
        "    \"The child looked up and asked, 'Who is that man?'\",\n",
        "    \"Rain tapped against the windows all night long.\",\n",
        "    \"I picked up the mirror and saw something behind me.\",\n",
        "    \"Everyone said the house was haunted, but we didn't believe them.\",\n",
        "    \"They disappeared without leaving a trace.\",\n",
        "    \"The diary ended mid-sentence.\",\n",
        "    \"He found the key inside a hollow book.\",\n",
        "    \"The train stopped in the middle of nowhere.\",\n",
        "    \"She always counted the stairs. Today there was one extra.\",\n",
        "    \"I've never been afraid of dolls, until now.\",\n",
        "    \"The floorboards creaked, but no one was there.\",\n",
        "    \"I saw a shadow crawl across the ceiling.\",\n",
        "    \"My dreams have started to bleed into reality.\",\n",
        "    \"I don't remember how I got this scar.\",\n",
        "    \"The silence was deafening.\",\n",
        "    \"I opened my eyes and saw her standing there.\",\n",
        "    \"My reflection moved before I did.\",\n",
        "    \"There was something alive inside the walls.\",\n",
        "    \"I saw myself standing across the street.\",\n",
        "    \"The wind carried a voice I recognized.\",\n",
        "    \"He was staring at me from the other side of the glass.\",\n",
        "    \"They buried her last week, but she was on the porch today.\",\n",
        "    \"It started as a game, but we can't stop playing.\",\n",
        "    \"The voices stopped when I turned off the radio.\",\n",
        "    \"We made a deal. Now it's time to pay.\",\n",
        "    \"Nobody remembers what happened that night.\",\n",
        "    \"He smiled, but his eyes were empty.\",\n",
        "    \"The news said it was just a storm.\",\n",
        "    \"There was a name written in blood on the mirror.\",\n",
        "    \"Something is wrong with the moon tonight.\",\n",
        "    \"I feel watched. Even when I'm alone.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calcular_perplexity(model, tokenizer, texto, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids)\n",
        "        logits = outputs[\"logits\"]\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "    loss = loss_fn(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
        "\n",
        "    return torch.exp(loss).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def distribucion_lexica(textos, tokenizer=None, nivel=\"palabra\"):\n",
        "    counter = Counter()\n",
        "\n",
        "    for texto in textos:\n",
        "        if nivel == \"token\" and tokenizer:\n",
        "            tokens = tokenizer.tokenize(texto)\n",
        "        else:\n",
        "            tokens = texto.lower().split()\n",
        "        counter.update(tokens)\n",
        "\n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def densidad_lexica(textos):\n",
        "    total_palabras = 0\n",
        "    total_unicas = set()\n",
        "\n",
        "    for texto in textos:\n",
        "        palabras = texto.lower().split()\n",
        "        total_palabras += len(palabras)\n",
        "        total_unicas.update(palabras)\n",
        "\n",
        "    if total_palabras == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return len(total_unicas) / total_palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def repeticion_media(textos):\n",
        "    repes = []\n",
        "\n",
        "    for texto in textos:\n",
        "        palabras = texto.lower().split()\n",
        "        total = len(palabras)\n",
        "        unicas = len(set(palabras))\n",
        "\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        repetidas = total - unicas\n",
        "        repes.append(repetidas / total)\n",
        "\n",
        "    if not repes:\n",
        "        return 0.0\n",
        "\n",
        "    return sum(repes) / len(repes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calcular_entropia_media(model, tokenizer, textos):\n",
        "    model.eval()\n",
        "    entropias = []\n",
        "\n",
        "    for texto in textos:\n",
        "        inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids)\n",
        "            logits = outputs[\"logits\"]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            log_probs = torch.log(probs + 1e-12)\n",
        "\n",
        "            entropia = -torch.sum(probs * log_probs, dim=-1)\n",
        "            media = entropia.mean().item()\n",
        "            entropias.append(media)\n",
        "\n",
        "    return sum(entropias) / len(entropias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalizar_counter(counter, vocab_total):\n",
        "    total = sum(counter.values())\n",
        "    return np.array([counter.get(tok, 0) / total for tok in vocab_total])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def jaccard_sim(c1, c2):\n",
        "    set1 = set(c1)\n",
        "    set2 = set(c2)\n",
        "    return len(set1 & set2) / len(set1 | set2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.special import rel_entr\n",
        "\n",
        "def kl_divergence(p, q):\n",
        "    return np.sum(rel_entr(p, q))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_similarity(p, q):\n",
        "    return dot(p, q) / (norm(p) * norm(q) + 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textos_base = [generate_text(modelo_base, tokenizer, prompt, max_new_tokens=80) for prompt in prompts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_base = distribucion_lexica(textos_base, tokenizer, nivel=\"token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "densidad_lexica_base = densidad_lexica(textos_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "repeticion_media_base = repeticion_media(textos_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropia_media_base = calcular_entropia_media(modelo_base, tokenizer, evaluation_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelo_lora = copy.deepcopy(modelo_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndy1MICpaHEf"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class LoRALayer(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.alpha * (x @ self.A @ self.B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5g2OvZ_VaHEh"
      },
      "outputs": [],
      "source": [
        "class LinearWithLoRA(torch.nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(\n",
        "            linear.in_features, linear.out_features, rank, alpha\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3N58b8RaHEi"
      },
      "outputs": [],
      "source": [
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, torch.nn.Linear) and any(x in name.lower() for x in [\"q\", \"k\", \"v\", \"proj\", \"fc\"]):\n",
        "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
        "        else:\n",
        "            replace_linear_with_lora(module, rank, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAYM7IXEaHEi",
        "outputId": "96c43cc6-c6ea-4313-ab67-361b5f81da2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters before: 838,359,040\n",
            "Total trainable parameters after: 0\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in modelo_lora.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters before: {total_params:,}\")\n",
        "\n",
        "for param in modelo_lora.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "total_params = sum(p.numel() for p in modelo_lora.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters after: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra4UTEZjaHEj",
        "outputId": "8e6c620f-0e65-476b-e234-557841f3fdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable LoRA parameters: 5,898,240\n"
          ]
        }
      ],
      "source": [
        "replace_linear_with_lora(modelo_lora, rank=16, alpha=16)\n",
        "\n",
        "total_params = sum(p.numel() for p in modelo_lora.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agLJxRgnaHEj",
        "outputId": "deadb1b6-615f-49f0-d9f1-bab211c41bc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x18c39071c30>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo_lora.to(device)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo_lora.load_state_dict(torch.load(\"modelo_lora.pth\", map_location=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textos_lora = [generate_text(modelo_lora, tokenizer, prompt, max_new_tokens=80) for prompt in prompts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_lora = distribucion_lexica(textos_lora, tokenizer, nivel=\"token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "densidad_lexica_lora = densidad_lexica(textos_lora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "repeticion_media_lora = repeticion_media(textos_lora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity base: 23.18\n"
          ]
        }
      ],
      "source": [
        "perplexitys_base = [calcular_perplexity(modelo_lora, tokenizer, texto) for texto in evaluation_texts]\n",
        "perplexity_base = sum(perplexitys_base) / len(prompts)\n",
        "\n",
        "print(f\"Perplexity base: {perplexity_base:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity LoRA: 24.01\n"
          ]
        }
      ],
      "source": [
        "perplexitys_lora = [calcular_perplexity(modelo_lora, tokenizer, texto) for texto in evaluation_texts]\n",
        "perplexity_lora = sum(perplexitys_lora) / len(prompts)\n",
        "\n",
        "print(f\"Perplexity LoRA: {perplexity_lora:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras más comunes base: [('.', 184), ('Ġthe', 177), ('Ċ', 160), (',', 158), ('Ġwas', 105), ('Ġto', 90), ('Ġa', 87), ('Ġand', 86), ('Ġin', 69), ('Ġhe', 68), ('Ġof', 59), ('Ġhis', 52), ('Ġhad', 51), ('Ġit', 48), ('ĠHe', 46), ('Ġbut', 40), ('Ġthat', 38), ('Ġat', 36), ('The', 34), ('ĠI', 33), ('Ġon', 31), (\"'t\", 30), ('Ġno', 29), ('Ġhim', 28), ('.\"', 28), ('Ġwith', 28), ('Ġsaid', 27), ('Ġ\"', 27), (\"'s\", 26), ('Ġbe', 24)]\n",
            "Palabras más comunes LoRA: [('.', 247), (',', 173), ('Ġthe', 157), ('Ġwas', 116), ('Ġa', 97), ('Ġto', 91), ('Ġand', 89), ('ĠI', 84), ('âĢ', 74), ('Ġit', 65), ('Ļ', 64), ('Ġof', 61), ('Ġin', 56), ('Ġbut', 49), ('Ġhis', 48), ('ĠIt', 46), ('Ġhad', 44), ('Ġhe', 41), ('Ġfor', 38), ('ĠHe', 38), ('Ġhim', 37), ('Ġonly', 35), ('Ġmy', 34), ('Ġas', 31), ('Ġon', 30), ('t', 30), ('Ġno', 30), ('ĠThe', 30), ('Ġat', 29), ('Ġthere', 28)]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Palabras más comunes base: {vocab_base.most_common(30)}\")\n",
        "print(f\"Palabras más comunes LoRA: {vocab_lora.most_common(30)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Densidad léxica base: 0.126\n",
            "Densidad léxica LoRA: 0.149\n",
            "Repetición media base: 2.43\n",
            "Repetición media LoRA: 1.78\n"
          ]
        }
      ],
      "source": [
        "print(f\"Densidad léxica base: {densidad_lexica_base:.3f}\")\n",
        "print(f\"Densidad léxica lora: {densidad_lexica_lora:.3f}\")\n",
        "\n",
        "print(f\"Repetición media base: {repeticion_media_base:.2f}\")\n",
        "print(f\"Repetición media lora: {repeticion_media_lora:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KL Divergence: 0.213\n",
            "Cosine Similarity: 0.761\n",
            "Jaccard Similarity: 0.597\n"
          ]
        }
      ],
      "source": [
        "vocab_total = list(set(vocab_base) | set(vocab_lora))\n",
        "\n",
        "vec_base = normalizar_counter(vocab_base, vocab_total)\n",
        "vec_lora = normalizar_counter(vocab_lora, vocab_total)\n",
        "\n",
        "print(\"KL Divergence:\", kl_divergence(vec_base, vec_lora))\n",
        "print(\"Cosine Similarity:\", cosine_similarity(vec_base, vec_lora))\n",
        "print(\"Jaccard Similarity:\", jaccard_sim(vocab_base, vocab_lora))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
